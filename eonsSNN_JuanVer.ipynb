{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "191f47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdbe3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e640b",
   "metadata": {},
   "source": [
    "Set up Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a00be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cardio_train.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8a2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['id','cardio']).values\n",
    "labels = df['cardio'].values\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87b765aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardioDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.x = torch.tensor(features, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee8d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CardioDataset(features, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dce864",
   "metadata": {},
   "source": [
    "Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9761f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#network parameters\n",
    "hyperParameters = {'crossover_rate':0.5,\n",
    "                   'merge_rate': 0,\n",
    "                   'mutation_rate':0.9,\n",
    "                   'num_mutations':7,\n",
    "                   'add_layer_rate':0.09,\n",
    "                   'delete_layer_rate':0.07,\n",
    "                   'randomize_weight_rate':0.16,\n",
    "                   'randomize_bias_rate':0.14,\n",
    "                   'randomize_beta_rate': 0.16,\n",
    "                   'selection_type':'tournament',\n",
    "                   'random_factor':0.1,\n",
    "                   'num_best':0,\n",
    "                   'population_size':6,\n",
    "                   'num_generations':100}\n",
    "nin = 11\n",
    "nout = 2\n",
    "beta = 0.95\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "num_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb050de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EONS:\n",
    "    def __init__(self,params):\n",
    "        self.template_network = None\n",
    "        self.startLayer = None\n",
    "        self.endLayer = None\n",
    "        self.pop = None\n",
    "        self.nin = None\n",
    "        self.nout = None\n",
    "        self.params = params\n",
    "        pass\n",
    "\n",
    "    def make_template_network(self,nin:int,nout:int):\n",
    "        self.nin = nin\n",
    "        self.nout = nout\n",
    "        return None\n",
    "    \n",
    "    def initWeights(self,n):\n",
    "        if isinstance(n,nn.Linear):\n",
    "            nn.init.xavier_uniform_(n.weight)\n",
    "            nn.init.zeros_(n.bias)\n",
    "        \n",
    "\n",
    "    def generatePopulation(self,):\n",
    "        pop = []\n",
    "        for i in range(self.params['population_size']):\n",
    "            layerToGenerate = random.randint(2,10)\n",
    "            neuronsPerLayer = [random.randint(50,1000) for i in range(layerToGenerate)]\n",
    "            \n",
    "            layers = [nn.Linear(self.nin,neuronsPerLayer[0]),snn.Leaky(beta=beta,spike_grad=spike_grad,init_hidden=True)]\n",
    "            for j in range(layerToGenerate-1):\n",
    "                layers.append(nn.Linear(neuronsPerLayer[j],neuronsPerLayer[j+1]))\n",
    "                layers.append(snn.Leaky(beta=random.uniform(0.5,0.95),spike_grad=spike_grad,init_hidden=True))\n",
    "            layers.append(nn.Linear(neuronsPerLayer[-1],self.nout))\n",
    "            layers.append(snn.Leaky(beta=beta,spike_grad=spike_grad,init_hidden=True,output=True))\n",
    "            net = nn.Sequential(*layers).to(device)\n",
    "            net.apply(self.initWeights)\n",
    "            net.metadata = {'layer_count':layerToGenerate,\n",
    "                            'neurons': neuronsPerLayer}\n",
    "            pop.append(net)\n",
    "        self.pop = pop\n",
    "        return pop\n",
    "    \n",
    "    def forward_pass(self,net,num_steps:int,data):\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "        utils.reset(net)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            spk_out,mem_out = net(data)\n",
    "            spk_rec.append(spk_out)\n",
    "            mem_rec.append(mem_out)\n",
    "        return torch.stack(spk_rec),torch.stack(mem_rec)\n",
    "    \n",
    "    def fitness(self,net):\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            acc = 0\n",
    "            for batch_x,batch_y in dataloader:\n",
    "                data = batch_x.to(device)\n",
    "                targets = batch_y.to(device)\n",
    "                output,_ = self.forward_pass(net,num_steps,data)\n",
    "\n",
    "                acc += SF.accuracy_rate(output, targets) * output.size(1)\n",
    "                total += output.size(1)\n",
    "            bign = 1\n",
    "            for i in range(0,len(net),2):\n",
    "                layer = net[i]\n",
    "                if hasattr(layer,\"out_features\"):\n",
    "                    bign = max(bign,layer.out_features)\n",
    "            w1,w2,w3 = 0.75,0.05,0.2\n",
    "            wt = w1+w2+w3\n",
    "            sizeNet = len(net) - 4\n",
    "        return (acc/total * (w1/wt))+ (1/sizeNet * (w3/wt)) + (1/bign * (w2/wt))\n",
    "    \n",
    "    def tournamentSelection(self,fits): \n",
    "        best = []\n",
    "        for i in range(len(fits)):\n",
    "            tourney = random.sample(fits,3)\n",
    "            tourney.sort(reverse=True)\n",
    "            best.append(tourney[0])\n",
    "        best.sort(reverse=True)\n",
    "        return [fits.index(i) for i in best] # return indices of best fits\n",
    "    \n",
    "    def crossoverChild1(self,layerNet:nn.Sequential,weightNet:nn.Sequential):\n",
    "        c1 = [i for i in layerNet]\n",
    "        for i in range(len(c1)):\n",
    "            if(isinstance(i,nn.Linear)):\n",
    "                rows = min(weightNet[i].weight.size(0),c1[i].weight.size(0))\n",
    "                cols = min(weightNet[i].weight.size(1),c1[i].weight.size(1))\n",
    "                c1.weight.data[:rows,:cols] = weightNet.weight.data[:rows,:cols].clone()\n",
    "                biaslen = min(weightNet[i].bias.size(0),c1[i].bias.size(0))\n",
    "                c1.bias.data[:biaslen] = weightNet.bias.data[:biaslen].clone()\n",
    "        return nn.Sequential(*c1)\n",
    "    \n",
    "    def crossoverChild2(self,layerNet:nn.Sequential,weightNet:nn.Sequential):\n",
    "        c2 = [i for i in layerNet]\n",
    "        for i in range(len(weightNet)):\n",
    "            if(isinstance(i,nn.Linear)):\n",
    "                rows = min(weightNet[i].weight.size(0),c2[i].weight.size(0))\n",
    "                cols = min(weightNet[i].weight.size(1),c2[i].weight.size(1))\n",
    "                c2.weight.data[:rows,:cols] = weightNet.weight.data[:rows,:cols].clone()\n",
    "                biaslen = min(weightNet[i].bias.size(0),c2[i].bias.size(0))\n",
    "                c2.bias.data[:biaslen] = weightNet.bias.data[:biaslen].clone()\n",
    "        return nn.Sequential(*c2)\n",
    "            \n",
    "    def crossover(self,net1:nn.Sequential,net2:nn.Sequential):\n",
    "        smallNet = net1\n",
    "        bigNet = net2\n",
    "        if(len(net1)>len(net2)):\n",
    "            smallNet = net2\n",
    "            bigNet = net1\n",
    "        return self.crossoverChild1(smallNet,bigNet),self.crossoverChild2(bigNet,smallNet)\n",
    "    \n",
    "    def addLayer(nNet:nn.Sequential,cNet:nn.Sequential):\n",
    "        pass\n",
    "    \n",
    "    def mutate(self,net:nn.Sequential):\n",
    "        nNet = [net[0],net[1]]\n",
    "        cNet = net\n",
    "        lastLayer = [net[-2],net[-1]]\n",
    "        with torch.no_grad():\n",
    "            for i in range(2,len(cNet)-2):\n",
    "                layer = cNet[i]\n",
    "                if random.random() < self.params['add_layer_rate'] and isinstance(layer,nn.Linear):\n",
    "                    pass\n",
    "                if random.random() < self.params['delete_layer_rate'] and isinstance(layer,nn.Linear):\n",
    "                    pass\n",
    "                if random.random() < self.params['randomize_weight_rate'] and isinstance(layer,nn.Linear):\n",
    "                    nn.init.xavier_normal_(layer.weight)\n",
    "                if random.random() < self.params['randomize_bias_rate'] and isinstance(layer,nn.Linear):\n",
    "                    layer.bias.uniform_(-1,1)\n",
    "                if random.random() < self.params['randomize_beta_rate'] and isinstance(layer,snn.Leaky):\n",
    "                    layer = snn.Leaky(beta=random.uniform(0.5,0.95),spike_grad=spike_grad,init_hidden=True)\n",
    "                nNet.append(layer)\n",
    "        for i in lastLayer:\n",
    "            nNet.append(i)\n",
    "        return nn.Sequential(*nNet)\n",
    "    \n",
    "    def reproduction(self,pop:list[nn.Sequential],fits:list):\n",
    "        newPop = []\n",
    "        for i in range(self.params['num_best']):\n",
    "            newPop.append(pop[i])    \n",
    "        for i in range(self.params['num_best'],len(fits),2):\n",
    "            p1,p2 = pop[fits[i]],pop[fits[i+1]]\n",
    "            c1,c2 = self.crossover(p1,p2)\n",
    "\n",
    "            if random.random() < self.params['mutation_rate']:\n",
    "                c1 = self.mutate(c1)\n",
    "            if random.random() < self.params['mutation_rate']:\n",
    "                c2 = self.mutate(c2)\n",
    "            newPop.append(c1)\n",
    "            newPop.append(c2)\n",
    "        for i in range(len(newPop)):\n",
    "            newPop[i] = newPop[i].to(device) \n",
    "        return newPop\n",
    "    \n",
    "    def getAvgFit(self,pop,results):\n",
    "        fits = [pop[i] for i in results]\n",
    "        return np.mean(fits)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ecd6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "eons = EONS(hyperParameters)\n",
    "eons.make_template_network(nin,nout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1f556",
   "metadata": {},
   "source": [
    "Setting up all populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9b13e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = eons.generatePopulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5d40d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0 Avg Fit:0.4248 Best Fit: 0.4554\n",
      "Generation: 1 Avg Fit:0.4792 Best Fit: 0.4792\n",
      "Generation: 2 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 3 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 4 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 5 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 6 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 7 Avg Fit:0.4748 Best Fit: 0.4748\n",
      "Generation: 8 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 9 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 10 Avg Fit:0.4794 Best Fit: 0.4804\n",
      "Generation: 11 Avg Fit:0.4909 Best Fit: 0.4961\n",
      "Generation: 12 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 13 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 14 Avg Fit:0.4533 Best Fit: 0.4533\n",
      "Generation: 15 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 16 Avg Fit:0.4757 Best Fit: 0.4757\n",
      "Generation: 17 Avg Fit:0.5034 Best Fit: 0.5138\n",
      "Generation: 18 Avg Fit:0.5319 Best Fit: 0.537\n",
      "Generation: 19 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 20 Avg Fit:0.4827 Best Fit: 0.4827\n",
      "Generation: 21 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 22 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 23 Avg Fit:0.4827 Best Fit: 0.4836\n",
      "Generation: 24 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 25 Avg Fit:0.4759 Best Fit: 0.4759\n",
      "Generation: 26 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 27 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 28 Avg Fit:0.4731 Best Fit: 0.4742\n",
      "Generation: 29 Avg Fit:0.4811 Best Fit: 0.4811\n",
      "Generation: 30 Avg Fit:0.4906 Best Fit: 0.4906\n",
      "Generation: 31 Avg Fit:0.4933 Best Fit: 0.4986\n",
      "Generation: 32 Avg Fit:0.4755 Best Fit: 0.4755\n",
      "Generation: 33 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 34 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 35 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 36 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 37 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 38 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 39 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 40 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 41 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 42 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 43 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 44 Avg Fit:0.4748 Best Fit: 0.4748\n",
      "Generation: 45 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 46 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 47 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 48 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 49 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 50 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 51 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 52 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 53 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 54 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 55 Avg Fit:0.471 Best Fit: 0.471\n",
      "Generation: 56 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 57 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 58 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 59 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 60 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 61 Avg Fit:0.4754 Best Fit: 0.4754\n",
      "Generation: 62 Avg Fit:0.479 Best Fit: 0.4809\n",
      "Generation: 63 Avg Fit:0.4809 Best Fit: 0.4809\n",
      "Generation: 64 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 65 Avg Fit:0.4745 Best Fit: 0.4746\n",
      "Generation: 66 Avg Fit:0.4748 Best Fit: 0.4748\n",
      "Generation: 67 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 68 Avg Fit:0.4723 Best Fit: 0.4723\n",
      "Generation: 69 Avg Fit:0.4753 Best Fit: 0.4754\n",
      "Generation: 70 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 71 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 72 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 73 Avg Fit:0.4747 Best Fit: 0.4747\n",
      "Generation: 74 Avg Fit:0.4626 Best Fit: 0.4626\n",
      "Generation: 75 Avg Fit:0.4767 Best Fit: 0.4767\n",
      "Generation: 76 Avg Fit:0.4765 Best Fit: 0.4765\n",
      "Generation: 77 Avg Fit:0.4783 Best Fit: 0.4783\n",
      "Generation: 78 Avg Fit:0.4784 Best Fit: 0.4784\n",
      "Generation: 79 Avg Fit:0.4756 Best Fit: 0.4756\n",
      "Generation: 80 Avg Fit:0.4747 Best Fit: 0.4749\n",
      "Generation: 81 Avg Fit:0.4754 Best Fit: 0.4754\n",
      "Generation: 82 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 83 Avg Fit:0.4953 Best Fit: 0.4953\n",
      "Generation: 84 Avg Fit:0.4749 Best Fit: 0.4749\n",
      "Generation: 85 Avg Fit:0.471 Best Fit: 0.4714\n",
      "Generation: 86 Avg Fit:0.4711 Best Fit: 0.4714\n",
      "Generation: 87 Avg Fit:0.4746 Best Fit: 0.4746\n",
      "Generation: 88 Avg Fit:0.4746 Best Fit: 0.4746\n",
      "Generation: 89 Avg Fit:0.4756 Best Fit: 0.4759\n",
      "Generation: 90 Avg Fit:0.4748 Best Fit: 0.4748\n",
      "Generation: 91 Avg Fit:0.4747 Best Fit: 0.4747\n",
      "Generation: 92 Avg Fit:0.473 Best Fit: 0.473\n",
      "Generation: 93 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 94 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 95 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 96 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 97 Avg Fit:0.4885 Best Fit: 0.4885\n",
      "Generation: 98 Avg Fit:0.4753 Best Fit: 0.4753\n",
      "Generation: 99 Avg Fit:0.4662 Best Fit: 0.4662\n"
     ]
    }
   ],
   "source": [
    "num_epoch = eons.params['num_generations']\n",
    "for i in range(num_epoch):\n",
    "    fits = [eons.fitness(net) for net in pop]\n",
    "    results = eons.tournamentSelection(fits)\n",
    "    avgFit = eons.getAvgFit(fits,results)\n",
    "    print('Generation: '+str(i)+' Avg Fit:'+ str(round(avgFit,4)) +' Best Fit: '+ str(round(fits[results[0]],4)))\n",
    "    pop = eons.reproduction(pop,results)\n",
    "bestNet = pop[results[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a5718c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61b7bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48824285714285715\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    for batch_x,batch_y in dataloader:\n",
    "        data = batch_x.to(device)\n",
    "        targets = batch_y.to(device)\n",
    "        output,_ = eons.forward_pass(bestNet,num_steps,data)\n",
    "\n",
    "        acc += SF.accuracy_rate(output, targets) * output.size(1)\n",
    "        total += output.size(1)\n",
    "    print(acc/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
