{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9202d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snnTorch Imports\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "\n",
    "# Torch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Python Libary Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from snntorch import utils\n",
    "import random\n",
    "import configparser\n",
    "\n",
    "# Script Imports\n",
    "from test_config import getHyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957b5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#network parameters\n",
    "nin = 2\n",
    "nout = 1\n",
    "rand_range_start = 1\n",
    "rand_range_end = 10\n",
    "beta = 0.95\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EONS:\n",
    "    def __init__(self,params):\n",
    "        self.params = params\n",
    "        self.template_network = None\n",
    "        pass\n",
    "    def make_template_network(self,nin:int,nout:int):\n",
    "        hidden = random.randint(rand_range_start,rand_range_end)\n",
    "        hidden2 = random.randint(rand_range_start,rand_range_end)\n",
    "        hidden3 = random.randint(rand_range_start,rand_range_end)\n",
    "        net = nn.Sequential(nn.Linear(nin,hidden),\n",
    "                            snn.Leaky(beta=beta,spike_grad=spike_grad),\n",
    "                            nn.Linear(hidden,hidden2),\n",
    "                            snn.Leaky(beta=beta,spike_grad=spike_grad),\n",
    "                            nn.Linear(hidden2,hidden3),\n",
    "                            snn.Leaky(beta=beta,spike_grad=spike_grad),\n",
    "                            nn.Linear(hidden3,nout),\n",
    "                            snn.Leaky(beta=beta,spike_grad=spike_grad))\n",
    "        self.template_network = net\n",
    "        return None\n",
    "    \n",
    "    def add_node(self):\n",
    "        \"\"\"\n",
    "        This method adds a neuron to a randomly selected hidden layer and updates the \n",
    "        in_features to the next layer accordingly.\n",
    "        \"\"\"\n",
    "        # Don't do anything if the network didn't initialize properly\n",
    "        if self.template_network is None:\n",
    "            print(\"Template network not initialized\")\n",
    "            return\n",
    "        \n",
    "        # Find indicies for all linear layers\n",
    "        layer_indices = [i for i, layer in enumerate(self.template_network) if isinstance(layer, nn.Linear)]\n",
    "\n",
    "        # Exclude input and output layers\n",
    "        if (len(layer_indices) <= 2):\n",
    "               print(\"Not enough layers to modify (only input/output layers present)\")\n",
    "\n",
    "        hidden_layer_indices = layer_indices[1:-1] # Only hidden layers\n",
    "        selected_index = random.choice(hidden_layer_indices) # Select random layer from hidden layer list\n",
    "        next_index = layer_indices[layer_indices.index(selected_index) + 1] # Get the next layer so that we can update the input\n",
    "\n",
    "        # Get the layers\n",
    "        linear = self.template_network[selected_index]\n",
    "        next_linear = self.template_network[next_index]\n",
    "\n",
    "        in_feat= linear.in_features # Keeping in features the same\n",
    "        new_out_feat = linear.out_features + 1 # Adding neuron to the out\n",
    "\n",
    "        # Creating updated hidden layer\n",
    "        new_linear = nn.Linear(in_feat, new_out_feat)\n",
    "\n",
    "        # Ensuring it keeps the same weights and biases\n",
    "        with torch.no_grad():\n",
    "             new_linear.weight[:linear.out_features] = linear.weight # Copies weights from old layer to new one\n",
    "             new_linear.bias[:linear.out_features] = linear.bias # Copies bias value\n",
    "\n",
    "        # Repeat for the next hidden layer. This ensures that the output of prev layer matches input of next layer\n",
    "        next_out = next_linear.out_features\n",
    "        new_next_linear = nn.Linear(new_out_feat, next_out)\n",
    "        with torch.no_grad():\n",
    "            new_next_linear.weight[:, :linear.out_features] = next_linear.weight # Copies only the part of the next layer's weight matrix that connects to the existing neurons\n",
    "            new_next_linear.bias = next_linear.bias # Copies biases for output layer neuron\n",
    "\n",
    "        # Replacing both layers in the sequential\n",
    "        layers = list(self.template_network)\n",
    "        layers[selected_index] = new_linear\n",
    "        layers[next_index] = new_next_linear\n",
    "        \n",
    "        self.template_network = nn.Sequential(*layers)\n",
    "        print(f\"Added a neuron to output of layer {selected_index} and updated input to layer {next_index}\")\n",
    "\n",
    "    def remove_node(self):\n",
    "        \"\"\"\n",
    "        This method removes a neuron from a randomly selected hidden layer.\n",
    "        The in_features of the next layer is updated accordingly.\n",
    "        If there isn't enough neurons in the layer to remove (if # of neurons is <= 1),\n",
    "        the function simply returns and no mutation occurs. \n",
    "        \"\"\"\n",
    "        # Don't do anything if the network didn't initialize properly\n",
    "        if self.template_network is None:\n",
    "            print(\"Template network not initialized\")\n",
    "            return\n",
    "        \n",
    "        # Find indicies for all linear layers\n",
    "        layer_indices = [i for i, layer in enumerate(self.template_network) if isinstance(layer, nn.Linear)]\n",
    "\n",
    "        # Exclude input and output layers\n",
    "        if (len(layer_indices) <= 2):\n",
    "               print(\"Not enough layers to modify (only input/output layers present)\")\n",
    "\n",
    "        hidden_layer_indices = layer_indices[1:-1] # Only hidden layers\n",
    "        selected_index = random.choice(hidden_layer_indices) # Select random layer from hidden layer list\n",
    "        next_index = layer_indices[layer_indices.index(selected_index) + 1] # Get the next layer so that we can update the input\n",
    "\n",
    "        # Get the layers\n",
    "        linear = self.template_network[selected_index]\n",
    "        next_linear = self.template_network[next_index]\n",
    "\n",
    "        # Only continue if there are more than one neuron in the out features\n",
    "        if (linear.out_features <= 1):\n",
    "            print(f\"Not enough neurons in layer {selected_index}. Cannot remove neuron.\")\n",
    "            return\n",
    "\n",
    "        in_feat= linear.in_features # Keeping in features the same\n",
    "        new_out_feat = linear.out_features - 1 # Removing neuron to the out\n",
    "\n",
    "        # Creating updated hidden layer\n",
    "        new_linear = nn.Linear(in_feat, new_out_feat)\n",
    "\n",
    "        # Ensuring it keeps the same weights and biases\n",
    "        with torch.no_grad():\n",
    "             new_linear.weight[:] = linear.weight[:new_out_feat] # Keep the first N-1 neurons' weights\n",
    "             new_linear.bias[:] = linear.bias[:new_out_feat] # Copies bias values except the one being removed\n",
    "\n",
    "        # Repeat for the next hidden layer. This ensures that the output of prev layer matches input of next layer\n",
    "        next_out = next_linear.out_features\n",
    "        new_next_linear = nn.Linear(new_out_feat, next_out)\n",
    "        with torch.no_grad():\n",
    "            new_next_linear.weight[:, :] = next_linear.weight[:, :new_out_feat] # Copies all output rows, but only the first new_out_feat input columns\n",
    "            new_next_linear.bias = next_linear.bias # Copies biases for output layer neuron\n",
    "\n",
    "        # Replacing both layers in the sequential\n",
    "        layers = list(self.template_network)\n",
    "        layers[selected_index] = new_linear\n",
    "        layers[next_index] = new_next_linear\n",
    "        \n",
    "        self.template_network = nn.Sequential(*layers) # Update network\n",
    "        print(f\"Removed a neuron to output of layer {selected_index} and updated input to layer {next_index}\")\n",
    "\n",
    "    def update_node_param(self):\n",
    "        \"\"\"\n",
    "        This method udpates the weights and bias of one randomly selected neuron in a randomly selected\n",
    "        hidden layer.\n",
    "\n",
    "        NOTE: There are a couple of lines that are commented out. These lines were created for visualization purposes\n",
    "              so that I could see if the neuron parameters were really updating. If you want to see those results,\n",
    "              simply uncomment those lines and uncomment the necessary lines in the cell below this one. \n",
    "        \"\"\"\n",
    "        # Don't do anything if the network didn't initialize properly\n",
    "        if self.template_network is None:\n",
    "            print(\"Template network not initialized\")\n",
    "            return\n",
    "        \n",
    "        # Find indicies for all linear layers\n",
    "        layer_indices = [i for i, layer in enumerate(self.template_network) if isinstance(layer, nn.Linear)]\n",
    "\n",
    "        # Select random layer\n",
    "        selected_index = random.choice(layer_indices) \n",
    "        linear = self.template_network[selected_index]\n",
    "\n",
    "        # Select a random neuron and generate random weights/bias\n",
    "        new_weights = torch.rand(linear.in_features)\n",
    "        new_bias = torch.rand(1)\n",
    "        neuron_index = random.choice(range(linear.out_features))\n",
    "\n",
    "        #print(\"Newly generated weights and biases\")\n",
    "        #print(new_weights)\n",
    "        #print(new_bias)\n",
    "        \n",
    "        layers = list(self.template_network) # Convert network to list\n",
    "\n",
    "        #old_weights = layers[selected_index].weight[neuron_index].clone() \n",
    "        #old_bias = layers[selected_index].bias[neuron_index].clone() \n",
    "\n",
    "        # Update neuron weights and bias\n",
    "        with torch.no_grad():\n",
    "            layers[selected_index].weight[neuron_index] = new_weights\n",
    "            layers[selected_index].bias[neuron_index] = new_bias\n",
    "\n",
    "        self.template_network = nn.Sequential(*layers) # Updated network\n",
    "\n",
    "        print(f\"Updated neuron {neuron_index} in layer {selected_index}\")\n",
    "\n",
    "        #return selected_index, neuron_index, old_weights, old_bias \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated neuron 1 in layer 2\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "hyperparameters = getHyperParameters(config)\n",
    "\n",
    "test_eons = EONS(hyperparameters)\n",
    "test_eons.make_template_network(50, 10)\n",
    "print(test_eons.template_network, end=\"\\n\\n\")\n",
    "test_eons.add_node()\n",
    "print(test_eons.template_network, end=\"\\n\\n\")\n",
    "test_eons.remove_node()\n",
    "print(test_eons.template_network, end=\"\\n\\n\")\n",
    "test_eons.update_node_param()\n",
    "\n",
    "# UNCOMMENT THE LINES BELOW IF YOU WANT TO PRINT OUT RESULTS FROM UPDATE_NODE_PARAM() AND SEE UPDATES\n",
    "# layer_index, neuron_index, old_weights, old_bias = test_eons.update_node_param() \n",
    "# print(\"\\nWeights and Biases before the update\")\n",
    "# print(old_weights)\n",
    "# print(old_bias)\n",
    "\n",
    "# print(\"\\nWeights and Biases after the update\")\n",
    "# layers = list(test_eons.template_network)\n",
    "# print(layers[layer_index].weight[neuron_index])\n",
    "# print(layers[layer_index].bias[neuron_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
